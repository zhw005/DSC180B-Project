{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dir = \"../data/out/feature_engineered_loan_data.csv.zip\"\n",
    "zf = zipfile.ZipFile(loan_dir)\n",
    "loan = pd.read_csv(zf.open('feature_engineered_loan_data.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-74d59f74441c>:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X = loan.drop(['Target','Unnamed: 0'], 1)\n",
      "C:\\Users\\14388\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\14388\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier(objective = 'binary', predict_raw_score = True)\n",
    "\n",
    "X = loan.drop(['Target','Unnamed: 0'], 1)\n",
    "columns = X.columns\n",
    "X.columns = range(X.shape[1])\n",
    "y = loan[['Target']]\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state = 42)\n",
    "model = model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.columns = columns\n",
    "test_X.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9196649236452561"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_y = model.predict(test_X)\n",
    "accuracy_score(pred_test_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_X\n",
    "test_data['test_y'] = test_y\n",
    "test_data['predicted_y'] = pred_test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Fairness\n",
    "\n",
    "A classifier satisfies\n",
    "this definition if subjects in both protected and unprotected groups\n",
    "have equal probability of being assigned to the positive predicted\n",
    "class. \n",
    "\n",
    "P(d =\n",
    "1|G = m) = P(d = 1|G = f )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_group_fairness_m = test_data.loc[test_data['CODE_GENDER: M'] == 1].loc[test_data.predicted_y == 1].shape[0]/test_data.loc[test_data['CODE_GENDER: M'] == 1].shape[0]\n",
    "p_group_fairness_f = test_data.loc[test_data['CODE_GENDER: M'] == 0].loc[test_data.predicted_y == 1].shape[0]/test_data.loc[test_data['CODE_GENDER: M'] == 0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004101659830566949"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_group_fairness_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0018113445295426355"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_group_fairness_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive Parity\n",
    "\n",
    "A classifier satisfies this definition if both protected and unprotected\n",
    "groups have equal PPV – the probability of a subject with positive predictive value to truly belong to the positive class. \n",
    "\n",
    "P(Y = 1|d = 1,G = m) = P(Y = 1|d = 1,G = f )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_predictive_parity_m = test_data.loc[test_data['CODE_GENDER: M'] == 1].loc[test_data.predicted_y == 1].loc[test_data.test_y == 1].shape[0]\\\n",
    "                        /test_data.loc[test_data['CODE_GENDER: M'] == 1].loc[test_data.predicted_y == 1].shape[0]\n",
    "p_predictive_parity_f = test_data.loc[test_data['CODE_GENDER: M'] == 0].loc[test_data.predicted_y == 1].loc[test_data.test_y == 1].shape[0]\\\n",
    "                        /test_data.loc[test_data['CODE_GENDER: M'] == 0].loc[test_data.predicted_y == 1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.48598130841121495, 0.5978260869565217)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_predictive_parity_m, p_predictive_parity_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False positive error rate balance(predictive equality)\n",
    "\n",
    " A classifier satisfies this definition if both\n",
    "protected and unprotected groups have equal FPR – the probability\n",
    "of a subject in the negative class to have a positive predictive value.\n",
    "\n",
    "P(d = 1|Y = 0,G = m) = P(d = 1|Y = 0,G = f )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_predictive_eqaulity_m = test_data.loc[test_data['CODE_GENDER: M'] == 1].loc[test_data.test_y == 0].loc[test_data.predicted_y == 1].shape[0]\\\n",
    "                        /test_data.loc[test_data['CODE_GENDER: M'] == 1].loc[test_data.test_y == 0].shape[0]\n",
    "p_predictive_eqaulity_f = test_data.loc[test_data['CODE_GENDER: M'] == 0].loc[test_data.test_y == 0].loc[test_data.predicted_y == 1].shape[0]\\\n",
    "                        /test_data.loc[test_data['CODE_GENDER: M'] == 0].loc[test_data.test_y == 0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.002346016038218734, 0.0007831848104481087)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_predictive_eqaulity_m, p_predictive_eqaulity_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False negative error rate balance(equal opportunity)\n",
    "\n",
    "A classifier satisfies this definition if both\n",
    "protected and unprotected groups have equal FNR – the probability\n",
    "of a subject in a positive class to have a negative predictive value.\n",
    "\n",
    "P(d = 0|Y = 1,G = m) = P(d = 0|Y = 1,G = f )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_predictive_opportunity_m = test_data.loc[test_data['CODE_GENDER: M'] == 1].loc[test_data.test_y == 1].loc[test_data.predicted_y == 0].shape[0]\\\n",
    "                        /test_data.loc[test_data['CODE_GENDER: M'] == 1].loc[test_data.test_y == 1].shape[0]\n",
    "p_predictive_opportunity_f = test_data.loc[test_data['CODE_GENDER: M'] == 0].loc[test_data.test_y == 1].loc[test_data.predicted_y == 0].shape[0]\\\n",
    "                        /test_data.loc[test_data['CODE_GENDER: M'] == 0].loc[test_data.test_y == 1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9803253878168747, 0.9844983089064262)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_predictive_opportunity_m, p_predictive_opportunity_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
